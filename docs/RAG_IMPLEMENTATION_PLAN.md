# ðŸš€ RAG Implementation Plan - Option C (Hybrid)

**Project:** tazagroupcore Support Chat with RAG  
**Approach:** Hybrid (Backend Direct + n8n Workflows)  
**Timeline:** 4 weeks  
**Status:** Planning Phase  
**Created:** October 31, 2025

---

## ðŸ“‹ Table of Contents

1. [Overview](#overview)
2. [Architecture](#architecture)
3. [MVP Scope](#mvp-scope)
4. [Implementation Phases](#implementation-phases)
5. [Technical Stack](#technical-stack)
6. [Database Schema](#database-schema)
7. [API Design](#api-design)
8. [Code Structure](#code-structure)
9. [Testing Strategy](#testing-strategy)
10. [Deployment Plan](#deployment-plan)
11. [Cost Estimation](#cost-estimation)
12. [Success Metrics](#success-metrics)

---

## ðŸŽ¯ Overview

### Objective
Build a production-ready RAG (Retrieval-Augmented Generation) system for support chat that:
- Provides accurate answers from internal knowledge base
- Reduces support agent workload by 60%
- Maintains <100ms search response time
- Handles 10,000+ documents with 99.9% uptime

### Current State
- âœ… AI Provider Management (ChatGPT, Grok, Gemini)
- âœ… Support Chat Settings & Widget
- âœ… NestJS backend with GraphQL
- âœ… Redis caching
- âœ… Multi-tenant architecture

### Target State
- âœ… Vector-based semantic search
- âœ… Automatic document ingestion pipeline
- âœ… Context-aware AI responses
- âœ… Knowledge base management UI
- âœ… Analytics & monitoring

---

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FRONTEND (Next.js 16)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Chat Widget   â”‚         â”‚  Admin Dashboard â”‚              â”‚
â”‚  â”‚  (Customer)    â”‚         â”‚  (Knowledge Mgmt)â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚           â”‚                          â”‚                         â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                          â”‚ GraphQL                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BACKEND (NestJS 11)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Support Chat Module                         â”‚  â”‚
â”‚  â”‚  â€¢ Message handling                                      â”‚  â”‚
â”‚  â”‚  â€¢ Conversation management                               â”‚  â”‚
â”‚  â”‚  â€¢ AI response generation â”€â”€â”€â”€â”                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                   â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              RAG Module (NEW) â­                          â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚  Services:                                               â”‚ â”‚
â”‚  â”‚  â€¢ VectorStoreService      â†’ Qdrant/Pinecone           â”‚ â”‚
â”‚  â”‚  â€¢ EmbeddingService        â†’ OpenAI/Gemini             â”‚ â”‚
â”‚  â”‚  â€¢ RAGSearchService        â†’ Semantic search           â”‚ â”‚
â”‚  â”‚  â€¢ DocumentParserService   â†’ PDF/DOCX/HTML            â”‚ â”‚
â”‚  â”‚  â€¢ ChunkingService         â†’ Text splitting           â”‚ â”‚
â”‚  â”‚  â€¢ ContextBuilderService   â†’ Prompt engineering       â”‚ â”‚
â”‚  â”‚                                                         â”‚ â”‚
â”‚  â”‚  Entities:                                              â”‚ â”‚
â”‚  â”‚  â€¢ RagDocument                                          â”‚ â”‚
â”‚  â”‚  â€¢ RagChunk                                             â”‚ â”‚
â”‚  â”‚  â€¢ RagSource                                            â”‚ â”‚
â”‚  â”‚                                                         â”‚ â”‚
â”‚  â”‚  Resolvers:                                             â”‚ â”‚
â”‚  â”‚  â€¢ RAGResolver (GraphQL)                               â”‚ â”‚
â”‚  â”‚  â€¢ WebhookController (REST)                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           Existing Modules (Integration)                 â”‚  â”‚
â”‚  â”‚  â€¢ AIProviderModule      â†’ Model selection              â”‚  â”‚
â”‚  â”‚  â€¢ RedisModule           â†’ Embedding cache              â”‚  â”‚
â”‚  â”‚  â€¢ PrismaModule          â†’ Metadata storage             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚ Webhook
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    n8n WORKFLOWS                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Workflow 1: Document Ingestion Pipeline                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Trigger â†’ Extract Text â†’ Chunk â†’ Embed â†’ Store â†’ Notify â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  Workflow 2: Scheduled Reindexing                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Cron â†’ Fetch Updates â†’ Process â†’ Upsert â†’ Report        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  Workflow 3: Quality Monitoring                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Cron â†’ Test Queries â†’ Evaluate â†’ Alert on Issues        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  Workflow 4: URL Crawler                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Schedule â†’ Crawl Docs â†’ Extract â†’ Send to Backend       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  Workflow 5: Performance Analytics                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Collect Metrics â†’ Aggregate â†’ Dashboard â†’ Weekly Report â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATA LAYER                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  PostgreSQL  â”‚  â”‚   Qdrant     â”‚  â”‚    Redis     â”‚         â”‚
â”‚  â”‚              â”‚  â”‚  (Vector DB) â”‚  â”‚   (Cache)    â”‚         â”‚
â”‚  â”‚ â€¢ Metadata   â”‚  â”‚ â€¢ Embeddings â”‚  â”‚ â€¢ Embeddings â”‚         â”‚
â”‚  â”‚ â€¢ Logs       â”‚  â”‚ â€¢ Similarity â”‚  â”‚ â€¢ Search     â”‚         â”‚
â”‚  â”‚ â€¢ Analytics  â”‚  â”‚   Search     â”‚  â”‚   Results    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ¯ MVP Scope

### âœ… In Scope (MVP)

#### Phase 1: Core RAG Engine (Week 1-2)
1. **Vector Storage Setup**
   - Qdrant self-hosted (Docker)
   - Collection creation & management
   - Index optimization

2. **Embedding Generation**
   - OpenAI text-embedding-3-small integration
   - Caching layer with Redis (TTL: 30 days)
   - Batch processing support

3. **Semantic Search**
   - Vector similarity search
   - Top-k retrieval (k=3-5)
   - Score threshold filtering (>0.7)
   - Metadata filtering

4. **Basic Document Management**
   - Text file upload (.txt, .md)
   - Manual chunking (500 tokens, 50 overlap)
   - CRUD operations via GraphQL
   - PostgreSQL metadata storage

5. **RAG Response Generation**
   - Context injection into prompts
   - Integration with AIProviderService
   - Fallback to direct AI when no context
   - Response source attribution

#### Phase 2: Document Pipeline (Week 3)
6. **Advanced Document Support**
   - PDF parsing (pdf-parse)
   - DOCX parsing (mammoth)
   - HTML parsing (cheerio)
   - Auto-chunking with overlap

7. **n8n Workflows**
   - Workflow 1: Document ingestion
   - Workflow 2: Scheduled reindexing
   - Webhook endpoint setup
   - Error handling & retry logic

8. **Admin UI (Frontend)**
   - Document upload interface
   - Knowledge base browser
   - Search testing tool
   - Basic analytics dashboard

#### Phase 3: Integration & Polish (Week 4)
9. **Support Chat Integration**
   - Auto-detect knowledge queries
   - RAG-enhanced responses
   - Source citations in chat
   - Confidence scoring

10. **Monitoring & Analytics**
    - Search query logging
    - Response quality metrics
    - Usage statistics
    - Error tracking

11. **Testing & Documentation**
    - Unit tests (80% coverage)
    - Integration tests
    - API documentation
    - User guide

### âŒ Out of Scope (MVP)

**Deferred to Post-MVP:**
- Multi-language support
- Advanced chunking strategies (recursive, semantic)
- Fine-tuned embedding models
- A/B testing framework
- Advanced analytics (user satisfaction, CSAT)
- Image/video document support
- Real-time collaboration on knowledge base
- Auto-categorization with ML
- GraphRAG / knowledge graphs
- Multi-modal RAG (text + images)

---

## ðŸ“… Implementation Phases

### **Phase 1: Core RAG Engine** (Week 1-2) ðŸ”¥

#### Week 1: Foundation

**Day 1-2: Vector Database Setup**
```bash
Tasks:
â–¡ Install Qdrant via Docker Compose
â–¡ Create collections schema
â–¡ Configure HNSW index parameters
â–¡ Test connection from NestJS
â–¡ Setup health checks

Deliverables:
- docker-compose.yml updated
- Qdrant running on :6333
- Test collection created
```

**Day 3-4: Embedding Service**
```bash
Tasks:
â–¡ Create EmbeddingService
â–¡ Integrate OpenAI API
â–¡ Implement Redis caching
â–¡ Add batch processing
â–¡ Error handling & retries

Deliverables:
- backend/src/rag/services/embedding.service.ts
- Unit tests
- Cache hit rate >90%
```

**Day 5-7: Vector Store Service**
```bash
Tasks:
â–¡ Create VectorStoreService
â–¡ Implement upsert operations
â–¡ Implement search operations
â–¡ Add metadata filtering
â–¡ Performance optimization

Deliverables:
- backend/src/rag/services/vector-store.service.ts
- Search latency <50ms
- Unit tests
```

#### Week 2: Search & Integration

**Day 8-10: RAG Search Service**
```bash
Tasks:
â–¡ Create RAGSearchService
â–¡ Implement semantic search
â–¡ Build context builder
â–¡ Add prompt engineering
â–¡ Integration with AIProviderService

Deliverables:
- backend/src/rag/services/rag-search.service.ts
- Context quality validation
- Integration tests
```

**Day 11-12: GraphQL API**
```bash
Tasks:
â–¡ Create Prisma schema for RAG
â–¡ Generate types & migrations
â–¡ Create GraphQL resolvers
â–¡ Create DTOs & validations
â–¡ Test via GraphQL Playground

Deliverables:
- backend/prisma/schema.prisma (RagDocument, RagChunk)
- backend/src/rag/resolvers/rag.resolver.ts
- API documentation
```

**Day 13-14: Document Parser**
```bash
Tasks:
â–¡ Create DocumentParserService
â–¡ Add TXT/MD support
â–¡ Implement chunking logic
â–¡ Add metadata extraction
â–¡ Error handling

Deliverables:
- backend/src/rag/services/document-parser.service.ts
- Support .txt, .md files
- Configurable chunk size
```

---

### **Phase 2: Document Pipeline** (Week 3) ðŸ”§

**Day 15-16: Advanced Document Support**
```bash
Tasks:
â–¡ Install pdf-parse, mammoth, cheerio
â–¡ Add PDF parsing
â–¡ Add DOCX parsing
â–¡ Add HTML parsing
â–¡ Optimize memory usage

Deliverables:
- Multi-format support
- Streaming for large files
- Memory usage <500MB per file
```

**Day 17-18: n8n Setup**
```bash
Tasks:
â–¡ Install n8n (Docker)
â–¡ Create workspace
â–¡ Configure credentials
â–¡ Test webhook connectivity
â–¡ Setup environment variables

Deliverables:
- docker-compose.yml (n8n service)
- n8n running on :5678
- Test workflow created
```

**Day 19-20: n8n Workflows**
```bash
Tasks:
â–¡ Workflow 1: Document Ingestion
â–¡ Workflow 2: Scheduled Reindexing
â–¡ Workflow 3: Quality Monitoring
â–¡ Test error scenarios
â–¡ Setup monitoring

Deliverables:
- 3 production workflows
- Error handling tested
- Logs & alerts configured
```

**Day 21: Webhook Integration**
```bash
Tasks:
â–¡ Create webhook controller
â–¡ Add authentication (API key)
â–¡ Validate payloads
â–¡ Queue processing (Bull)
â–¡ Test end-to-end flow

Deliverables:
- backend/src/rag/controllers/webhook.controller.ts
- Authentication working
- Queue dashboard
```

---

### **Phase 3: Integration & Polish** (Week 4) âœ¨

**Day 22-23: Support Chat Integration**
```bash
Tasks:
â–¡ Update SupportMessageService
â–¡ Add knowledge query detection
â–¡ Implement RAG response flow
â–¡ Add source citations
â–¡ Test conversation context

Deliverables:
- Enhanced support chat
- Source attribution UI
- Integration tests
```

**Day 24-25: Admin UI**
```bash
Tasks:
â–¡ Create Knowledge Base page
â–¡ Document upload component
â–¡ Search testing tool
â–¡ Document viewer
â–¡ Analytics dashboard

Deliverables:
- frontend/src/app/admin/knowledge-base/
- Upload working
- Search UI functional
```

**Day 26-27: Testing & Documentation**
```bash
Tasks:
â–¡ Write unit tests (80% coverage)
â–¡ Write integration tests
â–¡ Write E2E tests
â–¡ Update API documentation
â–¡ Write user guide

Deliverables:
- Test coverage report
- docs/RAG_API.md
- docs/RAG_USER_GUIDE.md
```

**Day 28: Deployment & Launch**
```bash
Tasks:
â–¡ Production environment setup
â–¡ Performance testing
â–¡ Load testing (100 concurrent)
â–¡ Security audit
â–¡ Go live!

Deliverables:
- Production deployment
- Monitoring dashboards
- Launch announcement
```

---

## ðŸ› ï¸ Technical Stack

### Backend Dependencies

```json
{
  "dependencies": {
    "@qdrant/js-client-rest": "^1.9.0",
    "openai": "^4.28.0",
    "@google/generative-ai": "^0.2.1",
    "pdf-parse": "^1.1.1",
    "mammoth": "^1.6.0",
    "cheerio": "^1.0.0-rc.12",
    "bull": "^4.12.0",
    "@nestjs/bull": "^10.0.1",
    "langchain": "^0.1.30",
    "tiktoken": "^1.0.10"
  },
  "devDependencies": {
    "@types/pdf-parse": "^1.1.4",
    "@types/bull": "^4.10.0"
  }
}
```

### Infrastructure

```yaml
# docker-compose.yml additions
services:
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./docker/qdrant/storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334

  n8n:
    image: n8nio/n8n:latest
    ports:
      - "5678:5678"
    volumes:
      - ./docker/n8n/data:/home/node/.n8n
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=admin
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - WEBHOOK_URL=http://backend:12001
```

---

## ðŸ—„ï¸ Database Schema

### Prisma Schema Extensions

```prisma
// backend/prisma/schema.prisma

// RAG Document Source
model RagSource {
  id          String   @id @default(uuid())
  name        String
  type        RagSourceType // FILE, URL, API, MANUAL
  description String?
  url         String?
  metadata    Json?
  isActive    Boolean  @default(true)
  
  documents   RagDocument[]
  
  createdAt   DateTime @default(now())
  updatedAt   DateTime @updatedAt
  createdBy   String?
  updatedBy   String?
  
  @@map("rag_sources")
}

// RAG Document (metadata only, vectors in Qdrant)
model RagDocument {
  id            String   @id @default(uuid())
  sourceId      String
  source        RagSource @relation(fields: [sourceId], references: [id], onDelete: Cascade)
  
  title         String
  content       String   @db.Text
  contentHash   String   // For deduplication
  fileType      String?  // pdf, docx, txt, html, md
  fileSize      Int?     // bytes
  filePath      String?
  
  language      String   @default("vi")
  category      String?
  tags          String[]
  
  // Vector metadata
  vectorId      String   @unique // ID in Qdrant
  chunkCount    Int      @default(0)
  embeddingModel String  @default("text-embedding-3-small")
  
  // Status
  status        RagDocumentStatus @default(PROCESSING)
  errorMessage  String?
  
  // Analytics
  searchCount   Int      @default(0)
  lastSearched  DateTime?
  qualityScore  Float?   // 0-1, based on usage
  
  chunks        RagChunk[]
  
  createdAt     DateTime @default(now())
  updatedAt     DateTime @updatedAt
  createdBy     String?
  updatedBy     String?
  
  @@index([sourceId])
  @@index([status])
  @@index([category])
  @@map("rag_documents")
}

// RAG Chunk (for granular tracking)
model RagChunk {
  id          String   @id @default(uuid())
  documentId  String
  document    RagDocument @relation(fields: [documentId], references: [id], onDelete: Cascade)
  
  content     String   @db.Text
  chunkIndex  Int      // Order in document
  
  // Vector metadata
  vectorId    String   @unique // ID in Qdrant
  embedding   String?  // Optional: store embedding as JSON array
  
  // Position in original document
  startChar   Int?
  endChar     Int?
  
  metadata    Json?
  
  createdAt   DateTime @default(now())
  
  @@index([documentId])
  @@index([chunkIndex])
  @@map("rag_chunks")
}

// RAG Search Log (for analytics)
model RagSearchLog {
  id              String   @id @default(uuid())
  
  query           String
  queryEmbedding  String?  // Optional
  
  // Results
  resultsCount    Int
  topDocumentId   String?
  topScore        Float?
  
  // Context
  conversationId  String?
  userId          String?
  
  // Performance
  searchTimeMs    Int
  embeddingTimeMs Int?
  totalTimeMs     Int
  
  // Quality
  userFeedback    Int?     // 1-5 rating
  wasHelpful      Boolean?
  
  createdAt       DateTime @default(now())
  
  @@index([createdAt])
  @@index([conversationId])
  @@map("rag_search_logs")
}

enum RagSourceType {
  FILE
  URL
  API
  MANUAL
}

enum RagDocumentStatus {
  PROCESSING
  ACTIVE
  INACTIVE
  ERROR
}
```

---

## ðŸ“¡ API Design

### GraphQL Schema

```graphql
# backend/src/schema.gql

# ============================================
# RAG Types
# ============================================

type RagDocument {
  id: ID!
  sourceId: String!
  source: RagSource!
  
  title: String!
  content: String!
  contentHash: String!
  fileType: String
  fileSize: Int
  filePath: String
  
  language: String!
  category: String
  tags: [String!]!
  
  vectorId: String!
  chunkCount: Int!
  embeddingModel: String!
  
  status: RagDocumentStatus!
  errorMessage: String
  
  searchCount: Int!
  lastSearched: DateTime
  qualityScore: Float
  
  chunks: [RagChunk!]!
  
  createdAt: DateTime!
  updatedAt: DateTime!
  createdBy: String
  updatedBy: String
}

type RagChunk {
  id: ID!
  documentId: String!
  document: RagDocument!
  
  content: String!
  chunkIndex: Int!
  vectorId: String!
  
  startChar: Int
  endChar: Int
  metadata: JSON
  
  createdAt: DateTime!
}

type RagSource {
  id: ID!
  name: String!
  type: RagSourceType!
  description: String
  url: String
  metadata: JSON
  isActive: Boolean!
  
  documents: [RagDocument!]!
  
  createdAt: DateTime!
  updatedAt: DateTime!
}

type RagSearchResult {
  document: RagDocument!
  chunk: RagChunk
  score: Float!
  highlights: [String!]
}

type RagResponseWithSources {
  response: String!
  sources: [RagSearchResult!]!
  confidence: Float!
  responseTimeMs: Int!
}

enum RagSourceType {
  FILE
  URL
  API
  MANUAL
}

enum RagDocumentStatus {
  PROCESSING
  ACTIVE
  INACTIVE
  ERROR
}

# ============================================
# RAG Inputs
# ============================================

input CreateRagDocumentInput {
  sourceId: String!
  title: String!
  content: String!
  fileType: String
  category: String
  tags: [String!]
  language: String
}

input UpdateRagDocumentInput {
  title: String
  content: String
  category: String
  tags: [String!]
  status: RagDocumentStatus
}

input SearchRagInput {
  query: String!
  limit: Int = 5
  scoreThreshold: Float = 0.7
  category: String
  language: String
}

input CreateRagSourceInput {
  name: String!
  type: RagSourceType!
  description: String
  url: String
  metadata: JSON
}

# ============================================
# RAG Queries
# ============================================

extend type Query {
  # Search knowledge base
  searchKnowledgeBase(input: SearchRagInput!): [RagSearchResult!]!
  
  # Get RAG documents
  ragDocument(id: ID!): RagDocument
  ragDocuments(
    skip: Int = 0
    take: Int = 20
    status: RagDocumentStatus
    category: String
    sourceId: String
  ): [RagDocument!]!
  
  # Get RAG sources
  ragSource(id: ID!): RagSource
  ragSources(isActive: Boolean): [RagSource!]!
  
  # Analytics
  ragAnalytics(from: DateTime, to: DateTime): RagAnalytics!
}

# ============================================
# RAG Mutations
# ============================================

extend type Mutation {
  # Document management
  createRagDocument(input: CreateRagDocumentInput!): RagDocument!
  updateRagDocument(id: ID!, input: UpdateRagDocumentInput!): RagDocument!
  deleteRagDocument(id: ID!): Boolean!
  
  # Bulk operations
  bulkIndexDocuments(documentIds: [ID!]!): BulkIndexResult!
  reindexAllDocuments: BulkIndexResult!
  
  # Source management
  createRagSource(input: CreateRagSourceInput!): RagSource!
  updateRagSource(id: ID!, input: CreateRagSourceInput!): RagSource!
  deleteRagSource(id: ID!): Boolean!
  
  # Generate RAG response (integrated with support chat)
  generateRagResponse(
    conversationId: ID!
    query: String!
  ): RagResponseWithSources!
  
  # Feedback
  submitRagFeedback(
    searchLogId: ID!
    rating: Int!
    wasHelpful: Boolean!
  ): Boolean!
}

# ============================================
# Supporting Types
# ============================================

type BulkIndexResult {
  total: Int!
  success: Int!
  failed: Int!
  errors: [String!]!
}

type RagAnalytics {
  totalDocuments: Int!
  totalChunks: Int!
  totalSearches: Int!
  averageSearchTime: Float!
  averageConfidence: Float!
  topQueries: [TopQuery!]!
  topDocuments: [TopDocument!]!
}

type TopQuery {
  query: String!
  count: Int!
  avgScore: Float!
}

type TopDocument {
  document: RagDocument!
  searchCount: Int!
  avgScore: Float!
}
```

### REST Webhook Endpoints

```typescript
// backend/src/rag/controllers/webhook.controller.ts

// POST /api/rag/webhook/ingest
interface IngestWebhookPayload {
  documentId?: string;
  title: string;
  content: string;
  sourceId: string;
  metadata?: Record<string, any>;
}

// POST /api/rag/webhook/reindex
interface ReindexWebhookPayload {
  documentIds?: string[];
  sourceIds?: string[];
  all?: boolean;
}

// POST /api/rag/webhook/status
interface StatusWebhookPayload {
  documentId: string;
  status: 'PROCESSING' | 'ACTIVE' | 'ERROR';
  errorMessage?: string;
}
```

---

## ðŸ“‚ Code Structure

```
backend/src/
â”œâ”€â”€ rag/                                 # ðŸ†• RAG Module
â”‚   â”œâ”€â”€ rag.module.ts                   # Module definition
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ vector-store.service.ts     # Qdrant integration
â”‚   â”‚   â”œâ”€â”€ embedding.service.ts        # OpenAI embeddings
â”‚   â”‚   â”œâ”€â”€ rag-search.service.ts       # Semantic search
â”‚   â”‚   â”œâ”€â”€ document-parser.service.ts  # File parsing
â”‚   â”‚   â”œâ”€â”€ chunking.service.ts         # Text chunking
â”‚   â”‚   â””â”€â”€ context-builder.service.ts  # Prompt engineering
â”‚   â”‚
â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”œâ”€â”€ rag-document.entity.ts
â”‚   â”‚   â”œâ”€â”€ rag-chunk.entity.ts
â”‚   â”‚   â””â”€â”€ rag-source.entity.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ dto/
â”‚   â”‚   â”œâ”€â”€ create-rag-document.input.ts
â”‚   â”‚   â”œâ”€â”€ update-rag-document.input.ts
â”‚   â”‚   â”œâ”€â”€ search-rag.input.ts
â”‚   â”‚   â””â”€â”€ create-rag-source.input.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ resolvers/
â”‚   â”‚   â”œâ”€â”€ rag.resolver.ts             # GraphQL queries/mutations
â”‚   â”‚   â””â”€â”€ rag-analytics.resolver.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â””â”€â”€ webhook.controller.ts       # n8n webhooks
â”‚   â”‚
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â””â”€â”€ document.processor.ts       # Bull queue processor
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ text-splitter.ts
â”‚   â”‚   â”œâ”€â”€ similarity-calculator.ts
â”‚   â”‚   â””â”€â”€ quality-scorer.ts
â”‚   â”‚
â”‚   â””â”€â”€ constants/
â”‚       â”œâ”€â”€ rag.constants.ts
â”‚       â””â”€â”€ prompts.constants.ts
â”‚
â”œâ”€â”€ support-chat/
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ support-message.service.ts  # ðŸ”„ Updated with RAG
â”‚
â””â”€â”€ ai-provider/
    â””â”€â”€ services/
        â””â”€â”€ ai-response.service.ts      # ðŸ”„ Enhanced for RAG

frontend/src/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ admin/
â”‚       â””â”€â”€ knowledge-base/             # ðŸ†• Knowledge Base UI
â”‚           â”œâ”€â”€ page.tsx                # List documents
â”‚           â”œâ”€â”€ upload/
â”‚           â”‚   â””â”€â”€ page.tsx            # Upload UI
â”‚           â”œâ”€â”€ [id]/
â”‚           â”‚   â”œâ”€â”€ page.tsx            # View document
â”‚           â”‚   â””â”€â”€ edit/
â”‚           â”‚       â””â”€â”€ page.tsx        # Edit document
â”‚           â””â”€â”€ search/
â”‚               â””â”€â”€ page.tsx            # Search testing
â”‚
â”œâ”€â”€ components/
â”‚   â””â”€â”€ rag/                            # ðŸ†• RAG Components
â”‚       â”œâ”€â”€ DocumentUploader.tsx
â”‚       â”œâ”€â”€ DocumentViewer.tsx
â”‚       â”œâ”€â”€ SearchTester.tsx
â”‚       â”œâ”€â”€ SourceCitation.tsx
â”‚       â””â”€â”€ AnalyticsDashboard.tsx
â”‚
â””â”€â”€ lib/
    â””â”€â”€ graphql/
        â””â”€â”€ rag.queries.ts              # ðŸ†• RAG GraphQL queries

n8n/
â”œâ”€â”€ workflows/
â”‚   â”œâ”€â”€ 01-document-ingestion.json      # ðŸ†• Workflow 1
â”‚   â”œâ”€â”€ 02-scheduled-reindex.json       # ðŸ†• Workflow 2
â”‚   â”œâ”€â”€ 03-quality-monitoring.json      # ðŸ†• Workflow 3
â”‚   â”œâ”€â”€ 04-url-crawler.json             # ðŸ†• Workflow 4
â”‚   â””â”€â”€ 05-analytics.json               # ðŸ†• Workflow 5
â”‚
â””â”€â”€ credentials/
    â”œâ”€â”€ backend-api-key.json
    â””â”€â”€ openai-api-key.json
```

---

## ðŸ§ª Testing Strategy

### Unit Tests (Target: 80% coverage)

```typescript
// backend/src/rag/services/__tests__/embedding.service.spec.ts
describe('EmbeddingService', () => {
  it('should generate embeddings', async () => {
    const text = 'Hello world';
    const embedding = await embeddingService.generateEmbedding(text);
    expect(embedding).toHaveLength(1536); // text-embedding-3-small
  });

  it('should cache embeddings in Redis', async () => {
    const text = 'Cached text';
    await embeddingService.generateEmbedding(text);
    const cached = await redisService.get(`embedding:${hash(text)}`);
    expect(cached).toBeDefined();
  });

  it('should batch process embeddings', async () => {
    const texts = ['Text 1', 'Text 2', 'Text 3'];
    const embeddings = await embeddingService.batchGenerateEmbeddings(texts);
    expect(embeddings).toHaveLength(3);
  });
});

// backend/src/rag/services/__tests__/rag-search.service.spec.ts
describe('RAGSearchService', () => {
  it('should find similar documents', async () => {
    const query = 'How to reset password?';
    const results = await ragSearch.searchSimilarDocuments(query, 3);
    expect(results).toHaveLength(3);
    expect(results[0].score).toBeGreaterThan(0.7);
  });

  it('should build context from results', async () => {
    const query = 'Pricing information';
    const response = await ragSearch.generateRAGResponse('conv-123', query);
    expect(response).toContain('pricing');
  });
});
```

### Integration Tests

```typescript
// backend/src/rag/__tests__/rag-integration.spec.ts
describe('RAG Integration', () => {
  it('should ingest document end-to-end', async () => {
    const doc = await createDocument({
      title: 'Test Doc',
      content: 'Test content...',
    });
    
    // Wait for processing
    await waitForStatus(doc.id, 'ACTIVE');
    
    // Search should return the document
    const results = await searchKnowledgeBase('Test content');
    expect(results[0].document.id).toBe(doc.id);
  });

  it('should handle webhook from n8n', async () => {
    const response = await request(app)
      .post('/api/rag/webhook/ingest')
      .send({
        title: 'Webhook Doc',
        content: 'From n8n',
        sourceId: 'source-1',
      })
      .expect(201);
    
    expect(response.body.id).toBeDefined();
  });
});
```

### E2E Tests

```typescript
// frontend/tests/e2e/knowledge-base.spec.ts
import { test, expect } from '@playwright/test';

test('should upload and search document', async ({ page }) => {
  await page.goto('/admin/knowledge-base/upload');
  
  // Upload file
  await page.setInputFiles('input[type="file"]', 'test-doc.txt');
  await page.click('button:has-text("Upload")');
  
  // Wait for processing
  await expect(page.locator('text=ACTIVE')).toBeVisible({ timeout: 10000 });
  
  // Search
  await page.goto('/admin/knowledge-base/search');
  await page.fill('input[name="query"]', 'test content');
  await page.click('button:has-text("Search")');
  
  // Should find document
  await expect(page.locator('text=test-doc.txt')).toBeVisible();
});
```

### Performance Tests

```typescript
// backend/src/rag/__tests__/performance.spec.ts
describe('RAG Performance', () => {
  it('should search under 100ms', async () => {
    const start = Date.now();
    await ragSearch.searchSimilarDocuments('query', 5);
    const duration = Date.now() - start;
    expect(duration).toBeLessThan(100);
  });

  it('should handle 100 concurrent searches', async () => {
    const promises = Array(100).fill(0).map(() =>
      ragSearch.searchSimilarDocuments('test', 5)
    );
    
    const start = Date.now();
    await Promise.all(promises);
    const duration = Date.now() - start;
    
    expect(duration).toBeLessThan(5000); // 5 seconds for 100 requests
  });
});
```

---

## ðŸš€ Deployment Plan

### Development Environment

```bash
# .env.development
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
OPENAI_API_KEY=sk-...
N8N_WEBHOOK_URL=http://localhost:5678/webhook
N8N_API_KEY=n8n-api-key-dev
REDIS_URL=redis://localhost:6379
```

### Staging Environment

```bash
# .env.staging
QDRANT_URL=http://qdrant-staging:6333
QDRANT_API_KEY=staging-key
OPENAI_API_KEY=sk-...
N8N_WEBHOOK_URL=https://n8n-staging.example.com/webhook
N8N_API_KEY=n8n-api-key-staging
REDIS_URL=redis://redis-staging:6379
```

### Production Environment

```bash
# .env.production
QDRANT_URL=http://qdrant-prod:6333
QDRANT_API_KEY=prod-secure-key
OPENAI_API_KEY=sk-prod-...
N8N_WEBHOOK_URL=https://n8n.tazagroupcore.com/webhook
N8N_API_KEY=n8n-api-key-prod-secure
REDIS_URL=redis://redis-prod:6379

# Performance tuning
QDRANT_GRPC_ENABLED=true
QDRANT_TIMEOUT=5000
REDIS_EMBEDDING_TTL=2592000  # 30 days
CHUNK_SIZE=500
CHUNK_OVERLAP=50
```

### Docker Compose Production

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  qdrant:
    image: qdrant/qdrant:v1.7.4
    restart: always
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__SERVICE__HTTP_PORT=6333
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  n8n:
    image: n8nio/n8n:latest
    restart: always
    ports:
      - "5678:5678"
    volumes:
      - n8n_data:/home/node/.n8n
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - N8N_HOST=${N8N_HOST}
      - N8N_PROTOCOL=https
      - NODE_ENV=production
      - WEBHOOK_URL=${BACKEND_URL}
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1'

volumes:
  qdrant_storage:
  n8n_data:
```

### Deployment Steps

```bash
# 1. Build backend with RAG module
cd backend
npm run build

# 2. Run database migrations
npx prisma migrate deploy

# 3. Start infrastructure
docker-compose -f docker-compose.prod.yml up -d qdrant n8n

# 4. Wait for services to be healthy
docker-compose -f docker-compose.prod.yml ps

# 5. Import n8n workflows
curl -X POST http://n8n:5678/api/workflows \
  -H "Authorization: Bearer $N8N_API_KEY" \
  -d @n8n/workflows/01-document-ingestion.json

# 6. Create Qdrant collection
curl -X PUT http://qdrant:6333/collections/knowledge_base \
  -H 'Content-Type: application/json' \
  -d '{
    "vectors": {
      "size": 1536,
      "distance": "Cosine"
    },
    "hnsw_config": {
      "m": 16,
      "ef_construct": 100
    }
  }'

# 7. Start backend
pm2 start dist/main.js --name backend-rag

# 8. Verify health
curl http://localhost:12001/health
curl http://localhost:6333/health

# 9. Test RAG endpoint
curl -X POST http://localhost:12001/graphql \
  -H 'Content-Type: application/json' \
  -d '{"query": "{ ragDocuments { id title } }"}'
```

---

## ðŸ’° Cost Estimation

### Infrastructure Costs (Monthly)

```
Vector Database (Qdrant):
â”œâ”€â”€ Option 1: Self-hosted (Docker)
â”‚   â”œâ”€â”€ Server: 2 CPU, 4GB RAM             = $20
â”‚   â”œâ”€â”€ Storage: 50GB SSD                  = $5
â”‚   â””â”€â”€ Total:                             = $25/month
â”‚
â”œâ”€â”€ Option 2: Qdrant Cloud (Recommended for scale)
â”‚   â”œâ”€â”€ Free tier: 1GB RAM, 4GB storage    = $0
â”‚   â”œâ”€â”€ Starter: 2GB RAM, 8GB storage      = $29/month
â”‚   â””â”€â”€ Pro: 4GB RAM, 50GB storage         = $99/month
â”‚
â””â”€â”€ MVP Choice: Self-hosted                = $25/month

n8n Automation:
â”œâ”€â”€ Option 1: Self-hosted (Docker)
â”‚   â”œâ”€â”€ Server: 1 CPU, 2GB RAM             = $10
â”‚   â””â”€â”€ Total:                             = $10/month
â”‚
â”œâ”€â”€ Option 2: n8n Cloud
â”‚   â”œâ”€â”€ Starter: 2,500 workflows/month     = $20/month
â”‚   â””â”€â”€ Pro: 10,000 workflows/month        = $50/month
â”‚
â””â”€â”€ MVP Choice: Self-hosted                = $10/month

AI API Costs (OpenAI):
â”œâ”€â”€ Embeddings (text-embedding-3-small)
â”‚   â”œâ”€â”€ Price: $0.00002 per 1K tokens
â”‚   â”œâ”€â”€ 10,000 docs Ã— 500 tokens avg       = 5M tokens
â”‚   â”œâ”€â”€ Initial indexing:                  = $0.10
â”‚   â”œâ”€â”€ Monthly updates (10% reindex):     = $0.01/month
â”‚   â””â”€â”€ Search queries (5K/month):         = $0.10/month
â”‚
â”œâ”€â”€ AI Responses (GPT-4-turbo)
â”‚   â”œâ”€â”€ Input: $0.01 per 1K tokens
â”‚   â”œâ”€â”€ Output: $0.03 per 1K tokens
â”‚   â”œâ”€â”€ 5,000 queries Ã— 2K context         = 10M input tokens  = $100
â”‚   â”œâ”€â”€ 5,000 queries Ã— 500 response       = 2.5M output tokens = $75
â”‚   â””â”€â”€ Total AI responses:                = $175/month
â”‚
â””â”€â”€ Total AI costs:                        = $175.21/month

Redis (Existing):
â””â”€â”€ Already included in infrastructure     = $0 additional

PostgreSQL (Existing):
â””â”€â”€ Metadata storage (~500MB)              = $0 additional

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL MONTHLY COST (MVP):                  = $210/month

Breakdown:
- Infrastructure: $35/month (Qdrant + n8n)
- AI API: $175/month (embeddings + responses)
- Existing services: $0 (Redis, PostgreSQL)
```

### Cost Optimization Strategies

```
1. Embedding Cache (Redis):
   - Cache hit rate: 90%
   - Savings: $0.09/month â†’ $0.01/month (90% reduction)

2. Batch Processing:
   - Batch embeddings: 50-100 docs at once
   - API efficiency: 30% reduction in costs

3. Free Tier Usage:
   - Qdrant Cloud free tier: 1GB (5K-10K docs)
   - OpenAI free credits: $5/month for new accounts

4. Alternative Models:
   - Use Gemini for responses: 50% cheaper
   - Self-host embeddings (sentence-transformers): 100% free
   
5. Smart Routing:
   - Only use RAG for knowledge queries (30% of all queries)
   - Direct AI for general chat (70% of queries)
   - Estimated savings: $50/month

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPTIMIZED MONTHLY COST:                    = $120-150/month
```

### Scaling Projections

```
Scenario 1: Small Business (Current MVP)
â”œâ”€â”€ Documents: 10,000
â”œâ”€â”€ Users: 500
â”œâ”€â”€ Queries: 5,000/month
â””â”€â”€ Cost: $150/month

Scenario 2: Medium Business (6 months)
â”œâ”€â”€ Documents: 50,000
â”œâ”€â”€ Users: 2,000
â”œâ”€â”€ Queries: 20,000/month
â””â”€â”€ Cost: $400/month

Scenario 3: Large Enterprise (1 year)
â”œâ”€â”€ Documents: 200,000
â”œâ”€â”€ Users: 10,000
â”œâ”€â”€ Queries: 100,000/month
â”œâ”€â”€ Qdrant Cloud Pro: $99/month
â”œâ”€â”€ n8n Cloud Pro: $50/month
â”œâ”€â”€ AI API: $1,500/month
â””â”€â”€ Cost: $1,650/month
```

---

## ðŸ“Š Success Metrics

### Phase 1 Success Criteria (Week 1-2)

```
Technical Metrics:
âœ“ Vector search latency < 50ms (p95)
âœ“ Embedding generation < 200ms per doc
âœ“ Cache hit rate > 90%
âœ“ Document ingestion < 5 seconds per doc
âœ“ 80% unit test coverage
âœ“ Zero critical bugs

Functional Metrics:
âœ“ Successfully index 100 test documents
âœ“ Search returns relevant results (manual validation)
âœ“ GraphQL API responds correctly
âœ“ Error handling works as expected
```

### Phase 2 Success Criteria (Week 3)

```
Technical Metrics:
âœ“ PDF parsing accuracy > 95%
âœ“ n8n workflows execute without errors
âœ“ Webhook latency < 500ms
âœ“ Queue processing < 1 minute per document

Functional Metrics:
âœ“ Upload PDF/DOCX/HTML successfully
âœ“ Auto-chunking produces logical segments
âœ“ Scheduled reindexing runs every 24 hours
âœ“ Monitoring detects and alerts on failures
```

### Phase 3 Success Criteria (Week 4)

```
Technical Metrics:
âœ“ End-to-end search latency < 100ms
âœ“ Support chat integration works seamlessly
âœ“ Admin UI loads < 2 seconds
âœ“ 100 concurrent users supported

Functional Metrics:
âœ“ Support agents can upload documents
âœ“ Customers receive RAG-enhanced answers
âœ“ Source citations are accurate
âœ“ Analytics dashboard shows real data

Business Metrics:
âœ“ 30% of support queries answered by RAG
âœ“ Customer satisfaction score > 4/5
âœ“ Average handling time reduced by 20%
```

### Long-term KPIs (Post-MVP)

```
Performance KPIs:
- Search relevance (MRR - Mean Reciprocal Rank) > 0.8
- Answer accuracy (human evaluation) > 85%
- System uptime > 99.9%
- Average response time < 2 seconds

Business KPIs:
- Support ticket reduction: 40-60%
- First response time: < 30 seconds
- Customer self-service rate: 50%+
- Agent productivity: +30%

Quality KPIs:
- User feedback rating: > 4.2/5
- Answer relevance score: > 0.75
- Document coverage: 90% of common questions
- Update frequency: Weekly
```

---

## ðŸ“š Documentation Deliverables

### 1. Technical Documentation

```
docs/
â”œâ”€â”€ RAG_API.md                    # GraphQL API reference
â”œâ”€â”€ RAG_ARCHITECTURE.md           # System design & diagrams
â”œâ”€â”€ RAG_DEPLOYMENT.md             # Deployment guide
â””â”€â”€ RAG_TROUBLESHOOTING.md        # Common issues & solutions
```

### 2. User Documentation

```
docs/
â”œâ”€â”€ RAG_USER_GUIDE.md             # Admin user manual
â”œâ”€â”€ RAG_BEST_PRACTICES.md         # Content guidelines
â””â”€â”€ RAG_FAQ.md                    # Frequently asked questions
```

### 3. Developer Documentation

```
docs/
â”œâ”€â”€ RAG_DEVELOPMENT.md            # Development setup
â”œâ”€â”€ RAG_TESTING.md                # Testing guide
â””â”€â”€ RAG_CONTRIBUTING.md           # Contribution guidelines
```

### 4. n8n Workflows Documentation

```
n8n/docs/
â”œâ”€â”€ WORKFLOW_01_INGESTION.md      # Document ingestion workflow
â”œâ”€â”€ WORKFLOW_02_REINDEX.md        # Scheduled reindexing
â”œâ”€â”€ WORKFLOW_03_MONITORING.md     # Quality monitoring
â”œâ”€â”€ WORKFLOW_04_CRAWLER.md        # URL crawler
â””â”€â”€ WORKFLOW_05_ANALYTICS.md      # Performance analytics
```

---

## ðŸŽ¯ MVP Feature Checklist

### Must Have (P0) âœ…

```
Backend:
â–¡ Vector database setup (Qdrant)
â–¡ Embedding generation (OpenAI)
â–¡ Semantic search (cosine similarity)
â–¡ Document CRUD (GraphQL)
â–¡ Basic chunking (fixed size)
â–¡ PostgreSQL metadata storage
â–¡ Redis caching
â–¡ Error handling & logging

Frontend:
â–¡ Document upload UI
â–¡ Knowledge base browser
â–¡ Search testing tool
â–¡ Basic analytics dashboard

Integration:
â–¡ Support chat RAG integration
â–¡ Source citations in responses
â–¡ n8n document ingestion workflow
â–¡ n8n scheduled reindexing

Testing:
â–¡ Unit tests (80% coverage)
â–¡ Integration tests
â–¡ Manual QA
```

### Should Have (P1) ðŸ”¶

```
Backend:
â–¡ Advanced document formats (PDF, DOCX, HTML)
â–¡ Batch operations
â–¡ Quality scoring
â–¡ Search analytics logging

Frontend:
â–¡ Document editing
â–¡ Bulk upload
â–¡ Advanced search filters
â–¡ Real-time status updates

Integration:
â–¡ n8n quality monitoring
â–¡ n8n URL crawler
â–¡ Webhook authentication
```

### Nice to Have (P2) ðŸ’¡

```
Backend:
â–¡ Multi-language support
â–¡ Advanced chunking (semantic)
â–¡ Auto-categorization
â–¡ A/B testing framework

Frontend:
â–¡ Document preview
â–¡ Collaboration features
â–¡ Advanced analytics
â–¡ Export capabilities

Integration:
â–¡ n8n performance analytics
â–¡ Slack notifications
â–¡ Email reports
```

---

## ðŸš¨ Risk Management

### Technical Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Vector DB performance degradation | High | Medium | Load testing, index optimization, caching |
| OpenAI API rate limits | High | Low | Request queuing, fallback to cached results |
| Large file processing failures | Medium | Medium | Streaming, chunking, timeout handling |
| n8n workflow errors | Medium | Medium | Error handling, retry logic, monitoring |
| Embedding quality issues | High | Low | Use proven models, validate with test queries |

### Business Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| Low adoption by support agents | High | Medium | Training, UX improvements, feedback loop |
| Poor answer quality | High | Medium | Regular content updates, quality monitoring |
| High operational costs | Medium | Low | Cost optimization, usage monitoring |
| Data privacy concerns | High | Low | Encryption, access controls, compliance |

### Mitigation Strategies

```
1. Performance Monitoring:
   - Set up alerts for response time > 100ms
   - Monitor Qdrant resource usage
   - Track embedding API costs daily

2. Quality Assurance:
   - Weekly manual testing of top queries
   - Monthly content review
   - Quarterly user satisfaction surveys

3. Cost Control:
   - Daily cost tracking dashboard
   - Alerts for unusual spending
   - Monthly budget reviews

4. Disaster Recovery:
   - Daily Qdrant backups
   - Weekly PostgreSQL backups
   - Documented recovery procedures
```

---

## ðŸ“ž Support & Maintenance

### Post-Launch Support (Weeks 5-8)

```
Week 5: Monitoring & Optimization
- Monitor production metrics
- Fix critical bugs (P0)
- Performance tuning
- User feedback collection

Week 6: Content Building
- Upload initial knowledge base (500+ docs)
- Train support team
- Refine categorization
- Update documentation

Week 7: Enhancement
- Implement P1 features
- UI/UX improvements based on feedback
- Advanced analytics
- Integration improvements

Week 8: Stabilization
- Bug fixes (P1, P2)
- Performance optimization
- Documentation updates
- Prepare for scale
```

### Ongoing Maintenance (Monthly)

```
Technical Maintenance:
- Update dependencies
- Qdrant index optimization
- Redis cache cleanup
- Log rotation & cleanup
- Security patches

Content Maintenance:
- Review and update documents
- Remove outdated content
- Add new FAQs
- Improve low-performing answers

Performance Tuning:
- Analyze slow queries
- Optimize vector indexes
- Cache hit rate optimization
- Cost optimization review

Quality Assurance:
- Test critical user paths
- Review error logs
- User feedback analysis
- A/B test improvements
```

---

## ðŸŽ“ Training & Knowledge Transfer

### Developer Training (Week 1)

```
Topics:
1. RAG fundamentals (2 hours)
   - What is RAG?
   - Vector embeddings explained
   - Semantic search basics

2. Architecture walkthrough (2 hours)
   - System components
   - Data flow
   - API design

3. Hands-on coding (4 hours)
   - Set up local environment
   - Create a document
   - Run a search query
   - Debug common issues

Deliverables:
- Training slides
- Code examples
- Video recordings
```

### Support Team Training (Week 6)

```
Topics:
1. Knowledge base management (1 hour)
   - Upload documents
   - Organize content
   - Best practices

2. Search testing (30 minutes)
   - Test search queries
   - Interpret results
   - Provide feedback

3. Analytics dashboard (30 minutes)
   - Read metrics
   - Identify issues
   - Report problems

Deliverables:
- User manual
- Video tutorials
- Quick reference guide
```

---

## ðŸŽ‰ Go-Live Checklist

### Pre-Launch (Day -7)

```
â–¡ All P0 features tested and working
â–¡ Production environment configured
â–¡ Qdrant production instance ready
â–¡ n8n workflows deployed
â–¡ Database migrations run
â–¡ Security audit completed
â–¡ Performance testing passed (100 concurrent users)
â–¡ Backup & recovery tested
â–¡ Monitoring & alerts configured
â–¡ Documentation finalized
```

### Launch Day (Day 0)

```
â–¡ Deploy backend to production
â–¡ Deploy frontend to production
â–¡ Import initial knowledge base (500 docs)
â–¡ Verify all services healthy
â–¡ Test end-to-end user flow
â–¡ Announce to support team
â–¡ Monitor for 4 hours continuously
â–¡ Be ready for rollback if needed
```

### Post-Launch (Day +1 to +7)

```
â–¡ Monitor error rates (target: <1%)
â–¡ Monitor response times (target: <100ms)
â–¡ Collect user feedback
â–¡ Daily check-in meetings
â–¡ Document issues & resolutions
â–¡ Plan Week 5 improvements
â–¡ Celebrate success! ðŸŽŠ
```

---

## ðŸ“ Appendix

### A. Useful Resources

```
Documentation:
- Qdrant: https://qdrant.tech/documentation/
- LangChain: https://js.langchain.com/docs/
- OpenAI Embeddings: https://platform.openai.com/docs/guides/embeddings
- n8n: https://docs.n8n.io/

Tutorials:
- RAG from Scratch: https://www.pinecone.io/learn/retrieval-augmented-generation/
- Vector Databases: https://www.deeplearning.ai/short-courses/vector-databases-embeddings/

Papers:
- RAG Paper (Lewis et al.): https://arxiv.org/abs/2005.11401
- Dense Passage Retrieval: https://arxiv.org/abs/2004.04906
```

### B. Sample Prompts

```typescript
// prompts.constants.ts

export const RAG_SYSTEM_PROMPT = `You are a helpful customer support assistant for tazagroupcore.

Use the following knowledge base context to answer the user's question accurately:

{context}

Guidelines:
1. Answer ONLY based on the provided context
2. If the answer is not in the context, say "I don't have that information"
3. Cite sources by mentioning document titles
4. Be concise and friendly
5. Use Vietnamese language

Context:
{context}

Question: {question}

Answer:`;

export const RAG_FALLBACK_PROMPT = `You are a helpful customer support assistant.
The knowledge base doesn't have information about this question, but try to help based on general knowledge about customer support.

Question: {question}

Answer:`;
```

### C. Configuration Examples

```typescript
// rag.constants.ts

export const RAG_CONFIG = {
  // Chunking
  CHUNK_SIZE: 500,              // tokens
  CHUNK_OVERLAP: 50,            // tokens
  
  // Embeddings
  EMBEDDING_MODEL: 'text-embedding-3-small',
  EMBEDDING_DIMENSIONS: 1536,
  
  // Search
  DEFAULT_TOP_K: 5,
  SCORE_THRESHOLD: 0.7,         // 0-1, cosine similarity
  
  // Vector Store
  VECTOR_COLLECTION: 'knowledge_base',
  HNSW_M: 16,                   // HNSW graph links
  HNSW_EF_CONSTRUCT: 100,       // Construction quality
  
  // Cache
  EMBEDDING_CACHE_TTL: 30 * 24 * 60 * 60, // 30 days
  SEARCH_CACHE_TTL: 5 * 60,     // 5 minutes
  
  // Processing
  MAX_FILE_SIZE: 50 * 1024 * 1024, // 50MB
  BATCH_SIZE: 100,               // documents per batch
  
  // Monitoring
  LOG_SEARCH_QUERIES: true,
  TRACK_PERFORMANCE: true,
};
```

---

## âœ… Next Steps

### Immediate Actions (This Week)

1. **Review this plan with team** (1 hour)
   - Discuss timeline
   - Confirm resource allocation
   - Adjust scope if needed

2. **Setup development environment** (2 hours)
   - Install Qdrant locally
   - Install n8n locally
   - Test connectivity

3. **Create project structure** (1 hour)
   - Create folders
   - Initialize modules
   - Setup Git branches

4. **Kickoff meeting** (1 hour)
   - Assign responsibilities
   - Set up daily standups
   - Create project board

### Week 1 Goals

- [ ] Qdrant running and tested
- [ ] Embedding service working
- [ ] First successful vector search
- [ ] GraphQL API skeleton

### Week 2 Goals

- [ ] Document CRUD complete
- [ ] RAG search integrated
- [ ] Basic testing suite
- [ ] Demo to stakeholders

---

**Document Version:** 1.0  
**Last Updated:** October 31, 2025  
**Owner:** Development Team  
**Status:** Ready for Implementation ðŸš€

---

**Ready to start? Begin with Phase 1, Day 1: Vector Database Setup!**

Good luck! ðŸ’ª
